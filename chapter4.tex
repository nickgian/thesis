\chapter{Formally Verified Control-Flow Integrity Micro-Policy}
\label{ch:verified_cfi}

Using the micro-policies framework described in \ref{sec:framework} we
proved that the concrete machine instantiated with a \CFI micro-policy
like the one described in \ref{sec:cfi_fine} \ii{simulates} an
abstract machine that has \CFI by construction. We do this proof by
using the symbolic machine as an intermediate step, to prove backwards
simulation between the symbolic and the abstract machine and
afterwards by leveraging the framework of section \ref{sec:framework}
we obtain a backwards refinement between the concrete and the abstract
machine.

In addition, we provide an attacker model for all the machines used
and we prove that a property capturing the notion of \CFI holds even
when the attacker tampers with the machine, similarly to what is
proposed in \cite{AbadiBEL09}, but adapted to the setting of our
machines. We do this by first proving this property for the
abstract machine and then by using a generic preservation theorem
we developed we prove that this property is \emph{preserved} by
backwards refinement and thus transferring the property to the
symbolic and consequently to the concrete machine.

\section{Representing control-flow graphs}\label{sec:cfi_tags}

Our approach for enforcing \CFI, as explained in \ref{sec:cfi_fine},
requires that we encode the nodes in the control-flow graph in terms
of identifiers, which in turn are used to tag all sources and targets
of indirect control-flows.

At this point we take a detour, to point out an important design point
of the micro-policies framework and our \CFI micro-policy.  Throughout
both developments, a heavily parametric and modular approach was
taken. This parametric design is enabled by the use of the
\emph{Section} and \emph{Type Classes} mechanisms of Coq. As an
example, the node identifiers, along with a number of properties we
require of them are expressed by the following interface (defined in
terms of a type class):

\lstheader{id_class}{Interface of node identifiers}
Context {t : machine_types}.

Class cfi_id := {
  id         : eqType;

  word_to_id : word t -> option id;
  id_to_word : id -> word t;
  
  id_to_wordK : forall x, word_to_id (id_to_word x) = Some x;
  word_to_idK : forall w x, word_to_id w = Some x -> id_to_word x = w
                             
}.
\end{lstlisting}

The \emph{Context} command on the top of the code above, allows us to
\textit{assume} that there exists an instance of this interface.
In fact, the \emph{machine\_types} argument is just another type class,
serving as a specification of the various types of the machine (\EG the word 
size). This approach allowed us to abstract away from various details and
structure our proofs in a clean way.
In addition, we can easily instantiate a different machine with minimal changes
in our proofs and definitions (\EG instantiate the machine with a different word
size).

However, one drawback is that one wrong specification in a type class would
disallow us to instantiate it and would require that we go back and change
all parts that used this wrong specification (\EG in our case, the 
\emph{machine\_types} class was widely used). Therefore one should be careful
when doing heavy use of such mechanisms.

Returning to the identifiers, looking at the definition in \cref{id_class},
we require that the type of the identifiers \id is an Eqtype (has decidable
boolean equality) and that there exists conversion functions between elements
of type \word and \id, satisfying some constraints. 

\QUESTION{Should I give some intuition, as to why word\_to\_id is partial? Is it
obvious?}

As mentioned in \cref{sec:cfi_fine}, we check for violations of the
control-flow with respect to a binary relation (on the identifiers)
\CFG which represents the set of allowed (indirect) jumps. We can
extend this relation to precisely describe the control-flow of a
program, by lifting \CFG to a relation \SUCC{} on machine states, that
includes the set of allowed targets for the rest of the
instructions. Throughout this thesis we use \CFG to refer to the set
of allowed jumps. In our Coq development we assumed a translation of
the allowed jumps in form of a function on two identifiers.


\lstheader{cfg}{Function on ids representing the set of allowed jumps}
Variable cfg : id -> id -> bool.
\end{lstlisting}

In addition we defined a function valid\_jmp (referred to with the
notation \J) that expresses the set of allowed jumps between words, by
using the \emph{word\_to\_id} function.

\lstheader{valid_jmp}{Function on words representing the set of allowed jumps}
Definition valid_jmp w1 w2 :=
  match word_to_id w1, word_to_id w2 with
    | Some id1, Some id2 => cfg id1 id2
    | _, _ => false
  end.
\end{lstlisting}

\section{Control-Flow Integrity Property}\label{sec:cfi_property}

Our formalization includes a definition of \CFI, similar to the one found in
\cite{AbadiBEL09}, which we prove to be true of all our machines. The need for a
new definition arises from fundamental differences between our enforcement
mechanism on the concrete mechanism and the one used by Abadi \ETAL. In
particular, our enforcement-mechanism does not prevent a violation, instead
it can detect it after it has occurred by taking an arbitrary number of
``protected'' (monitor mode) steps before eventually bringing the machine to a
halt. This does not have any impact on the security effectiveness of our
mechanism, it does however lead to a more complex definition and therefore
more complex proofs.

The definition of \CFI is further parameterized by an attacker model. We
model the attacker as a step relation (\stepa{}{}{}). Intuitively the attacker is
allowed to change any \emph{user-level} data but not the code of the program and
the \pc, as well as the tags in the case of a tagged machine. 
This limitations ensures that an attacker cannot directly circumvent the monitor
protection mechanism and our user-level policies (\NWC , \NXD and \CFI). To 
account for attacker steps, the stepping relation is extended as the union of 
the normal step relation (\stepn{}{}), as defined by the machine semantics, and
the attacker step relation (\stepa{}{}{}), as defined by the attacker model.

\begin{figure}[ht]
\centering
\begin{minipage}[b]{0.25\linewidth}
\centering
\infrule[]{\stepn{s}{s'}
  }{\step{s}{s'}}
\label{fig:step_stepn}
\end{minipage}
\hspace{0.5cm}
\begin{minipage}[b]{0.15\linewidth}
\centering
\infrule[]{\stepa{s}{s'}{}
  }{\step{s}{s'}}
\label{fig:step_stepa}
\end{minipage}
\caption{Step relation definition}
\end{figure}

We define a predicate \INITIAL{s}, where s is a machine state, that
states that s is an initial state. We use this predicate to express some
invariants that are preserved through execution (\EG the initial tagging scheme
for the memory). Finally we define a stopping predicate on an execution trace
that states that the machine is coming to a halt with respect to normal steps.

Since we want to instantiate the above parameters in a different way for
each of our machines, it makes sense to wrap them in a type class which
we will instantiate for each machine to get the corresponding definition
of \CFI.

\lstheader{cfi_machine}{Interface of a cfi\_machine}
Class cfi_machine := {
  state : Type;
  initial : state -> Prop;
  
  step : state -> state -> Prop;
  step_a : state -> state -> Prop;

  succ : state -> state -> bool;
  stopping : list state -> Prop
}.
\end{lstlisting}

For a machine of type cfi\_machine we give the following definitions:

\begin{definition}[Trace has CFI]\label{traceHasCfi}
  We say that an execution trace $s_0 \to s_1 \to \ldots \to s_n$ {\em has CFI}
  if for all $ i \in [0,\ldots,n)$ if \stepn{s_i}{s_{i+1}} then
  $(s_i,s_{i+1}) \in$ \SUCC .
\end{definition}

\QUESTION{The word relation for succ and cfg is strange since they are
booleans, is it ok, or does it confuse you, making you believe they are Props?}

The above definition corresponds to the one found in \cite{abadi2005}, however
it is stronger in the sense that it requires that steps that are in the
intersection of normal and attacker steps respect the control-flow. If we did
not allow for any violations then the above definition would be enough, but
since our enforcement mechanism allows for one violation we have to resort to a
weaker definition.

\begin{definition}[CFI]\label{cfi}
  We say that the machine
  $(\ii{State}, \ii{initial}, \to_n,\allowbreak \to_a, \SUCCm{}, \ii{stopping})$
  has \CFI with respect to the set of allowed indirect jumps \CFG
  if, for any execution starting from initial state $s_0$
  and producing a trace $s_0 \to \ldots \to s_n$, either
  \begin{enumerate}
  \item The whole trace has \CFI according to
    \cref{traceHasCfi}, or else
  \item There is some $i$ such that $s_i \to_n s_{i+1}$,
  and $(s_i, s_{i+1}) \not \in$ \SUCC{}, where
  the sub-traces $s_0 \to \ldots \to s_i$ and
  $s_{i+1} \to \ldots \to s_n$ both have CFI
  and the sub-trace $s_{i+1} \to \ldots \to s_n$ is stopping.
  \end{enumerate}
\end{definition}

\section{The Abstract Machine}\label{sec:abstract_cfi}

The abstract machine
has \CFI, \NXD and \NWC by construction and will serve as a 
specification for the symbolic and eventually the concrete machine that
implement \CFI through the tag-based system explained in the previous chapter.

Unlike the symbolic and the concrete machine, this abstract machine splits the 
memory into two disjoint memories, an instruction memory and a data memory. The
instruction memory is fixed (non-writable) and the machine uses this memory to
fetch instructions to execute, so \NWC and \NXD are enforced by construction.

In addition the state of the machine includes an \ok bit, indicating 
whether a control-flow violation has occurred or not. The rest of the machine
state is completed by a set of registers and a \pc register. We use a 5-tuple
notation for the state \acfistat{\imem}{\dmem}{\reg}{\pc}{\ok}, where the first
field is the instruction memory, the second the data memory, the third the
registers, the fourth is the pc register and the fifth is the \ok bit.

\subsection{Operational semantics}\label{sec:abstract_semantics}
Below is the step rule for the Store instruction, illustrating both \NWC and 
\NXD. Notice that the instruction is fetched by the instruction memory and
the store is done on the data memory.

\begin{figure}[!htpb]
\infrule[Store]{
  \imem[\pc] = i \andalso \ii{decode}~i = \ii{Store}~r_p~r_s \andalso
  \rd{\reg}{r_p} = p \\
  \rd{\reg}{r_s} = w \andalso
  \dmem' = \upd{\dmem}{p}{w}
  }{\step{\acfistat{\imem}{\dmem}{\reg}{\pc}{\ii{true}}}{
    \acfistat{\imem}{\dmem'}{\reg'}{\pc+1}{\ii{true}}}}
\caption{Step rule for Store instruction of abstract machine}
\end{figure}

In the above rule, the \ok bit is true for both the starting and the
resulting state. In fact, the machine can take a step only when the
\ok bit is set to true. In the above rule, the \ok bit is set to true
in the resulting state, indicating that no control-flow violation has
happened, as expected by the execution of a Store
instruction. Control-flow violations in the \NWC setting our machine
is executing, can only occur from \emph{indirect} jump instructions,
in our case the Jump and Jal instructions. Upon execution of a Jump or
Jal instruction, we consult \J (see \cref{valid_jmp}) to check
whether the change of control-flow is legal. If the jump is not
allowed according to \J then the jump is taken but the \ok bit is set
to false, which will halt the machine in the next step, as it is only
allowed to step when the \ok bit is set to true. Otherwise the \ok bit
will remain true.

\begin{figure}[!htpb]
\infrule[Jal]{
  \imem[\pc] = i \andalso \ii{decode}~i = \ii{Jal}~r \andalso
  \rd{\reg}{r} = \pc' \\
  \reg' = \upd{\reg}{\ra}{pc+1} \andalso
  \ii{ok} = (\pc,\pc') \in \Jm
  }{\step{\acfistat{\imem}{\dmem}{\reg}{\pc}{\ii{true}}}{
    \acfistat{\imem}{\dmem}{\reg'}{\pc'}{\ii{ok}}}}
\bigskip

\infrule[Jump]{
  \imem[\pc] = i \andalso \ii{decode}~i = \ii{Jump}~r \andalso
  \rd{\reg}{r} = \pc' \andalso
  \ii{ok} = (\pc,\pc') \in \Jm
  }{\step{\acfistat{\imem}{\dmem}{\reg}{\pc}{\ii{true}}}{
    \acfistat{\imem}{\dmem}{\reg'}{\pc'}{\ii{ok}}}}
\caption{Step rule for Jump and Jal instruction of abstract machine}
\end{figure}

As the abstract machine serves as a specification to a machine with
\CFI, a more intuitive definition of it would not include the \ok bit
and would only allow the Jump and Jal instructions to step if they do
not violate the control-flow graph. However, this abstract machine
would not allow for any violations to occur unlike our enforcement
mechanism for the symbolic and the concrete machine and would lead to
more complex simulation proofs, therefore we do not favor it.

The abstract machine also allows for monitor services to be included,
although the \CFI enforcement mechanism does not require any. We
assume that a monitor service is a privileged action and that it's
execution does not violate the control-flow of the program. Execution
of a monitor service is done simply by jumping to it's address, there
is no separate instruction. As with all other instructions, execution
of the monitor service is only allowed if the \ok bit is set to true.

\begin{figure}[H]
\infrule[Service]{
  \pc \not\in \ii{dom(\imem)} \andalso \pc \not\in \ii{dom(\dmem)} \andalso
  \ii{get\_service}~\pc = (addr,f) \\
  f~\acfistat{\imem}{\dmem}{\reg}{\pc}{\ii{true}}=
    \acfistat{\imem}{\dmem'}{\reg'}{\pc'}{\ii{true}}
  }{\stepn{\acfistat{\imem}{\dmem}{\reg}{\pc}{\ii{true}}}{
    \acfistat{\imem}{\dmem'}{\reg'}{\pc'}{\ii{true}}}}
\caption{Step rule for monitor services of abstract machine}
\end{figure}

\TODO{Put all rules in appendix?}

\subsection{Attacker model}\label{sec:abstract_attacker}

The attacker for the abstract machine is allowed to change the
contents of the data memory and the registers but not the rest of the state.

\begin{figure}[ht]
\infrule{
  \ii{dom}~\dmem = \ii{dom}~\dmem' \andalso
  \ii{dom}~\reg = \ii{dom}~\reg'
}{
  \acfistat{\imem}{\dmem}{\reg}{\pc}{\ok} \to_a^A
  \acfistat{\imem}{\dmem'}{\reg'}{\pc}{\ok}
}
\caption{Attacker model for the abstract machine}
\end{figure}

\subsection{Allowed control-flows for the abstract machine}
\label{sec:abstract_flow}

We can construct a function \SUCC{A} for the abstract machine
that represents the set of allowed control-flows for all
instructions, by extending the set of allowed jumps \CFG we
introduced earlier.

Below we give a specification of the \SUCC{A} function for the abstract machine,
in form of inference rules. A function is defined in the actual Coq development.

\begin{figure}[ht]
\infrule[IndirectFlows]{
  \imem[\pc] = i 
  \andalso \ii{decode}~i \in \lbrace \ii{Jal~r}, \ii{Jump~r} \rbrace
  \andalso (\pc,\pc') \in \Jm
  }{
  (\acfistat{\imem}{\dmem}{\reg}{\pc}{\ok} ,
  \acfistat{\imem}{\dmem'}{\reg'}{\pc'}{\ok}) \in \SUCCm{A}}
\bigskip

\infrule[ConditionalFlows]{
  \imem[\pc] = i 
  \andalso \ii{decode}~i = \ii{Bnz~r~imm}\\
   (\pc' = \pc + 1) \vee (\pc' = \pc + imm)
  }{
  (\acfistat{\imem}{\dmem}{\reg}{\pc}{\ok} ,
  \acfistat{\imem}{\dmem'}{\reg'}{\pc'}{\ok}) \in \SUCCm{A}}
\bigskip

\infrule[NormalFlows]{
  \imem[\pc] = i 
  \andalso 
  \ii{decode}~i \not\in \lbrace \ii{Jal~r}, \ii{Jump~r}, \ii{Bnz~r~imm}, 
  \varnothing \rbrace
  \\ \pc' = \pc + 1
  }{
  (\acfistat{\imem}{\dmem}{\reg}{\pc}{\ok} ,
  \acfistat{\imem}{\dmem'}{\reg'}{\pc'}{\ok}) \in \SUCCm{A}}
\bigskip

\infrule[ServiceFlows]{
  \imem[\pc] = \varnothing \andalso \dmem[\pc] = \varnothing\\
  \ii{get\_service}~\pc = (addr,f)
  }{
  (\acfistat{\imem}{\dmem}{\reg}{\pc}{\ok} ,
  \acfistat{\imem}{\dmem'}{\reg'}{\pc'}{\ok}) \in \SUCCm{A}}
\caption{Allowed control-flows for instructions of the abstract machine}
\end{figure}

Notice that a monitor service is allowed to return anywhere. As we
mentioned before, monitor services, execute in a protected by the
monitor environment where we assume that an attacker who can only
tamper the machine at the user level cannot interfere.

\subsection{Stopping predicate for the abstract machine}
\label{sec:abstract_stopping}

Finally, we define what it means for the abstract machine to be ``stopping'' by
defining a predicate on execution traces:
\begin{enumerate}
\item All states in the trace are stuck with respect to normal steps
  (\stepn{}{})
\item All steps in the trace are attacker steps (\stepa{}{}{})
\end{enumerate}

\subsection{CFI proof for the Abstract Machine}\label{abstract_proof}

Regarding initial states, we only require that the \ok bit is set to true.
We can now instantiate the class of the machines defined in 
\cref{cfi_machine}, with the abstract machine and that the abstract machine
has \CFI according to \cref{cfi}.
We first prove a helpful lemma.

\begin{lemma}[Step Intersection]
\label{attacker_no_v}
For all states \textit{st st'} such that \stepa{st}{st'}{A}
and \stepn{st}{st'}, $(\mathit{st},\mathit{st'}) \in \SUCCm{A}$.
\end{lemma}

\begin{proof}
~
\begin{itemize}
\item By the relation \stepn{st}{st'} we know that the \ok bit
of \textit{st} is set to true. 
\item The relation \stepa{st}{st'}{A} retains the \ok bit of
\textit{st}, therefore \textit{st'} has the \ok bit set to true.
\item It trivially follows from the definition of \SUCC{A} that
$(\mathit{st},\mathit{st'}) \in \SUCCm{A}$.
\end{itemize}
\end{proof}

\begin{theorem}[Abstract CFI]\label{CFIabstract}
The abstract machine has the \CFI property stated by \cref{cfi}.
\end{theorem}

\begin{proof} 
  ~ The proof proceeds by induction on the execution trace.
  \begin{itemize}
  \item \textbf{Base Case} In this case the execution trace is made up
    of a single step \step{st}{st'}. We proceed with case analysis on
    the step.
    \begin{itemize}
    \item \textbf{Attacker Step} By \cref{attacker_no_v} we
      note that an attacker step cannot be a normal step outside the
      \SUCC{A} relation. Thus in this case the whole trace has \CFI
      according to \cref{traceHasCfi}.
    \item \textbf{Normal Step} By case analysis, if
      $(\mathit{st},\mathit{st'}) \in \SUCCm{A}$ then trivially the
      whole trace has \CFI. Otherwise $(\mathit{st},\mathit{st'}) \not
      \in \SUCCm{A}$ and the sub-traces \textit{st} and \textit{st'}
      vacuously have \CFI. In addition the sub-trace \textit{st'} is
      stopping, as the \ok bit of \textit{st'} is set to false and the
      state is stuck with respect to normal steps.
    \end{itemize}
  \item \textbf{Inductive Case} In this case the execution trace is
    extended by an additional step at it's beginning
    $\mathbf{s_0 \to s_1} \to s_2 \to \ldots \to s_n$. 
    By the induction hypothesis either:
    \begin{itemize}
    \item The trace $s_1 \to s_2 \to \ldots \to s_n$ has \CFI, by case
      analysis if $(\mathit{s_0},\mathit{s_1}) \in \SUCCm{A}$ the
      whole trace has \CFI. Otherwise $(\mathit{s_0},\mathit{s_1})
      \not \in \SUCCm{A}$, the sub-trace $s_0$ vacuously has \CFI and
      the sub-trace $s_1 \to \ldots \to s_n$ has \CFI by the induction
      hypothesis. Additionally, the sub-trace $s_1 \to \ldots \to s_n$
      is stopping because:
      \begin{itemize}
        \item The whole trace is made up of attacker steps.
           Since $(\mathit{s_0},\mathit{s_1}) \not \in \SUCCm{A}$
           the \ok bit of $s_1$ will be set to false and a normal
           step is not allowed by the operational semantics,
           while attacker steps retain the \ok bit.
         \item The whole trace is stuck with respect to normal steps.
           Trivial from the above.
       \end{itemize}
     \item There exists a step $\stepn{s_{v1}}{s_{v2}}$ such that
       $(\mathit{s_{v1}},\mathit{s_{v2}}) \not \in \SUCCm{A}$ and
       the sub-traces $s_1 \to \ldots \to s_{v1}$ and
       $s_{v2} \to \ldots \to s_n$ both have \CFI and the later
       is also a stopping trace. 
       \begin{itemize}
         \item If $(\mathit{s_0},\mathit{s_1}) \in \SUCCm{A}$ then
           \cref{cfi} still holds and the sub-trace $s_1 \to \ldots 
           \to s_{v1}$ is extended by one step to $s_0 \to \ldots \to s_{v1}$.
         \item Otherwise the \ok bit for $s_1$ is set to false and the
           rest of the trace is stuck with respect to normal steps. However from
           the induction hypothesis we know that $\stepn{s_{v1}}{s_{v2}}$, which
           is a contradiction.
         \end{itemize}
       \end{itemize}
  \end{itemize}
\end{proof}

\section{The Symbolic  Machine}\label{sec:symbolic_cfi}

The symbolic machine was described in \cref{sec:symbolic}. Unlike the
abstract machine, the symbolic machine has one memory and the
distinction between data and executable instructions is made through
tags, in a fashion similar to what was shown in
\cref{sec:nwc_nxd,sec:cfi_fine}.  We instantiate the symbolic machine,
according to the aforementioned sections, with a set of tags
\TAGS{\DATA,\INSTR{\ii{id}}, \INSTR{\bot}} where id is drawn from the
class of identifiers \cref{cfi_id}.

\lstheader{cfi_tags}{Coq definition of Symbolic tags}
Context {ids : @cfi_id t}.

Inductive cfi_tag : Type :=
| INSTR : option id -> cfi_tag
| DATA  : cfi_tag.
\end{lstlisting}

Although enforcement of \CFI does not require any monitor services we
expose the monitor services mechanism and we check whether calls to
each monitor service are allowed or not according to the control-flow
graph. This is done by assuming a lookup-table of monitor services
where each entry has a tag that is used to check for control-flow
violations and a semantic function from symbolic state to symbolic
state which produces the new machine state after execution of the
system call, as shown in \cref{symbolic_step}.

We do not need any internal state for this micro-policy therefore,
only the transfer function is left to implement.

\subsection{Transfer Function}\label{sec:transfer_fun}

We implement the \TRANSFER function based on the rules found in
\ref{sec:cfi_fine}, using Gallina to define a function mapping
input vectors (mvector) to output vectors (rvector).

\lstheader{transfer_coq}{Transfer function for symbolic machine in Gallina}
Definition cfi_handler (ivec : Symbolic.IVec cfi_tags) : 
           option (Symbolic.OVec cfi_tags (Symbolic.op ivec)) :=
  match ivec return 
          option (Symbolic.OVec cfi_tags (Symbolic.op ivec)) with
  | mkIVec   (JUMP as op) (INSTR (Some n))  (INSTR (Some m))  _
  | mkIVec   (JAL  as op) (INSTR (Some n))  (INSTR (Some m))  _  =>
    if cfg n m then 
      Some (@mkOVec cfi_tags op (INSTR (Some m)) (default_rtag op))
    else 
      None
  | mkIVec   (JUMP as op)  DATA  (INSTR (Some n))  _
  | mkIVec   (JAL  as op)  DATA  (INSTR (Some n))  _   =>
    Some (@mkOVec cfi_tags op (INSTR (Some n)) (default_rtag op))
  | mkIVec   JUMP   DATA  (INSTR None)  _
  | mkIVec   JAL    DATA  (INSTR None)  _  =>
    None
  | mkIVec   STORE  (INSTR (Some n))  (INSTR (Some m))  [_ ; _ ; DATA] =>
    if cfg n m then Some (@mkOVec cfi_tags STORE DATA DATA) else None
  | mkIVec   STORE  DATA  (INSTR _)  [_ ; _ ; DATA]  =>
    Some (@mkOVec cfi_tags STORE DATA DATA)
  | mkIVec   STORE  _  _  _  => None
  | mkIVec   op     (INSTR (Some n))  (INSTR (Some m))  _  =>
    (* this includes op = SERVICE *)
    if cfg n m then 
      Some (@mkOVec cfi_tags op DATA (default_rtag op)) 
    else 
      None
  | mkIVec   op     DATA  (INSTR _)  _  =>
    (* this includes op = SERVICE, fall-throughs checked statically *)
    Some (@mkOVec cfi_tags op DATA (default_rtag op))
  | mkIVec _ _ _ _ => None
  end.
\end{lstlisting}
\TODO{Should I remove the aggressive capitilization above?
It may make it less painful on the eye...
Thanks to dependent types it also looks super ugly too,
probably make it pseudo-code at some point
}

Although, the rules in \cref{sec:cfi_fine} were fairly simply,
expressing them using Gallina's pattern matching increased their
size. We also experimented, with different ways of writing the
transfer function but we decided to stick with the definition above as
it's the most straightforward. It's worth to note that bugs in the
above definition were easily made apparent when proving theorems
involving the transfer function. In fact, an ``interesting''
experiment was to re-define the above function in a different way and
prove the two equivalent. It took two iterations before getting both
functions to agree and although for small definitions like the one
above, testing or manually reviewing the code will reveal most if not
all bugs, the importance of formal verification in software
engineering and critical software is made obvious even for definitions
that may seem trivial at first. The correctness of the transfer
function will come from simulation proofs between the abstract and the
symbolic machine.

\subsection{Attacker model}\label{sec:symbolic_attacker}

Similar to the abstract attacker, the symbolic attacker can change all words
tagged as \DATAname but not the ones tagged as \INSTRname. This is expressed by
the following relations:

\begin{figure}[htbp]
\infrule[AttackData]{
  }{\stepa{\atom{w_1}{\DATA}}{\atom{w_2}{\DATA}}{S}}
\bigskip
\infrule[AttackInstr]{
  }{\stepa{\atom{w_1}{\INSTR{id}}}{\atom{w_1}{\INSTR{id}}}{S}}
\caption{Attacker capabilities}
\label{fig:symbolic_attacker_atom}
\end{figure}

These attacker capabilities on symbolic atoms are lifted to
the memory and registers by a pointwise extension.
\TODO{be more specific about pointwise?}

\begin{figure}[htbp]
\infrule{
  \stepa{\mem}{\mem'}{S} \andalso
  \stepa{\reg}{\reg'}{S}
}{
  \stepa{\astat{\mem}{\reg}{\atom{\pc}{t_\pc}}{\extra}{}}
  {\astat{\mem'}{\reg'}{\atom{\pc}{t_\pc}}{\extra}{}}
  {S}
}
\caption{Attacker model for the Symbolic machine}
\label{fig:symbolic_attacker}
\end{figure}

\subsection{Allowed control-flows for the Symbolic Machine}
\label{sec:symbolic_flow}

Similar to the abstract machine of \cref{sec:abstract_flow}, we construct
\SUCC{S} for the symbolic machine (\cref{fig:symbolic_succ}) by
extending the set of allowed jumps \CFG.

\begin{figure}[htbp!]
\small
\infrule[IndirectFlows]{
  \mem[\pc] = \atom{\textit{i}}{\ti} 
  \andalso \textit{decode~i} \in \lbrace \ii{Jal~r}, \ii{Jump~r} \rbrace\\
  \mem[\pc'] = \atom{\textit{i}'}{\ti'} 
    \andalso \ti = \INSTR{src}
    \andalso \ti' = \INSTR{dst}\\
    (\textit{src},\textit{dst}) \in \CFGm
  }{
  (\acfistat{\mem}{\reg}{\pc}{\extra}{},
  \acfistat{\mem}{\reg}{\pc'}{\extra}{}) \in \SUCCm{S}}
\bigskip

\infrule[IndirectFlows2]{
  \mem[\pc] = \atom{\textit{i}}{\ti}
  \andalso \textit{decode~i} \in \lbrace \ii{Jal~r}, \ii{Jump~r} \rbrace\\
  \mem[\pc'] = \varnothing 
    \andalso \textit{get\_service}~\pc = (\ti',f)\\
    \ti = \INSTR{src} \andalso \ti' = \INSTR{dst}
    \\ (\textit{src},\textit{dst}) \in \CFGm
  }{
  (\acfistat{\mem}{\reg}{\pc}{\extra}{},
  \acfistat{\mem}{\reg}{\pc'}{\extra}{}) \in \SUCCm{S}}
\bigskip

\infrule[ConditionalFlows]{
  \mem[\pc] = \atom{\textit{i}}{\ti}
  \andalso \textit{decode~i} = \ii{Bnz~r~imm}\\
   (\pc' = \pc + 1) \vee (\pc' = \pc + imm)
  }{
  (\acfistat{\mem}{\reg}{\pc}{\extra}{},
  \acfistat{\mem}{\reg}{\pc'}{\extra}{}) \in \SUCCm{S}}
\bigskip

\infrule[NormalFlows]{
  \mem[\pc] = \atom{\textit{i}}{\ti}
  \andalso 
  \ii{decode}~i \not\in \lbrace \ii{Jal~r}, \ii{Jump~r}, \ii{Bnz~r~imm}, 
  \varnothing \rbrace
  \\ \pc' = \pc + 1
  }{
  (\acfistat{\mem}{\reg}{\pc}{\extra}{},
  \acfistat{\mem'}{\reg'}{\pc'}{\extra}{}) \in \SUCCm{S}}
\bigskip

\infrule[ServiceFlows]{
  \mem[\pc] = \varnothing \andalso \textit{get\_service}~\pc = (\ti',f)\\
  }{
  (\acfistat{\mem}{\reg}{\pc}{\extra}{},
  \acfistat{\mem'}{\reg'}{\pc'}{\extra'}{}) \in \SUCCm{S}}
\caption{Allowed control-flows for instructions of the symbolic machine}
\label{fig:symbolic_succ}
\end{figure}

\subsection{Initial states of the Symbolic Machine}
\label{sec:symbolic_initial}

For the symbolic machine, we do require that certain tagging
conventions are respected initially. Additionally we prove that
these initial conditions are invariants of the machine and they
are preserved at every (normal or attacker) step.

These invariants are required for backward simulation between
the symbolic and the abstract machine. More invariants may
be required for forward simulation.

\TODO{hopefully try to get to forward simulation and
see what's the situation there.}

\begin{definition}[Instructions Tagged]\label{instructions_tagged}
  ~ For all addresses \textit{addr} in the memory such that
  $$\mem[\mathit{addr}] = \atom{\mathit{i}}{\INSTR{id}}$$ \textit{addr}
  is in the domain of \emph{word\_to\_id} and additionally
  $$word\_to\_id ~\mathit{addr} = \mathit{id}$$
\end{definition}

\begin{definition}[Entry Points Tagged]\label{entry_tagged}
  ~ For all addresses \textit{addr} such that 
  \begin{align*}
  & \mem[addr] = \varnothing\\
  & get\_service~addr = (\mathit{it},f)\\
  & \mathit{it} = \INSTR{id}
  \end{align*}
  \textit{addr} is in the domain of \emph{word\_to\_id} and additionally
  $$word\_to\_id ~\mathit{addr} = \mathit{id}$$
\end{definition}

\begin{definition}[Valid Jumps Tagged]\label{valid_jmp_tagged}
  For all addresses \textit{saddr, taddr} such that
  $$(\mathit{saddr},\mathit{taddr}) \in \Jm$$ it holds that
  $$\exists \mathit{i}, \mem[saddr] = \atom{\mathit{i}}{\INSTR{(word\_to\_id~saddr)}} $$
  and either $$\exists \mathit{i'}, \mem[taddr]
  =\atom{\mathit{i'}}{\INSTR{word\_to\_id~taddr}}$$ or
  \begin{align*}
  & \mem[taddr] = \varnothing\\ 
  & \exists (\mathit{it},f), get\_service~addr = (\mathit{it},f)\\
  & \mathit{it} = \INSTR{(word\_to\_id~taddr)}
  \end{align*}
\end{definition}

We define a predicate \emph{initial} on symbolic states as
the conjunction of the above invariants and the
proposition that the tag on the \pc is set to \DATAname.

\lstheader{sym_initial}{Initial Symbolic states predicate}
Definition invariants st :=
  instructions_tagged (Symbolic.mem st) /\
  valid_jmp_tagged (Symbolic.mem st) /\
  entry_points_tagged (Symbolic.mem st) /\
  registers_tagged (Symbolic.regs st).

Definition initial (s : Symbolic.state t) :=
  (common.tag (Symbolic.pc s)) = DATA /\
  invariants s.
\end{lstlisting}

It's straightforward by the semantics of the step relations to prove
that both normal and attacker steps preserve each of the invariants.
We only need to assume that this holds for monitor services (\IE if we
were to provide some monitor services they would have to preserve
these invariants).

%write this in latex form and then use appendix for these.

\begin{lemma}[Symbolic Invariants preserved by normal steps]
\label{step_preserves_invariants}
For all symbolic states (\textit{st, st}'),
\begin{align*}
  & \mathit{invariants}~\mathit{st} \implies \\
  & \stepn{\mathit{st}}{\mathit{st}'} \implies \\
  & \mathit{invariants}~\mathit{st}'
\end{align*}
\end{lemma}

\begin{lemma}[Symbolic Invariants preserved by attacker steps]
\label{step_a_preserves_invariants}
For all symbolic states (\textit{st, st}'),
\begin{align*}
  & \mathit{invariants}~\mathit{st} \implies \\
  & \stepa{\mathit{st}}{\mathit{st}'}{S} \implies \\
  & \mathit{invariants}~\mathit{st}'
\end{align*}
\end{lemma}

\subsection{Stopping predicate for the Symbolic Machine}
\label{sec:symbolic_stopping}

Similar to the abstract machine, we say that an execution trace of the
symbolic machine is stopping if:
\begin{enumerate}
\item All states in the trace are stuck with respect to normal steps
  (\stepn{}{})
\item All steps in the trace are attacker steps (\stepa{}{}{})
\end{enumerate}

\subsection{Symbolic-Abstract backward simulation}
\label{sec:refinement_SA}

The Symbolic-Abstract backward simulation formally defines the
connection between the two machines. We prove a
1-backward simulation theorem for
both normal and attacker steps. This means that every
step of the symbolic machine is matched by one step
of the abstract machine.

\begin{definition}[1-Backward Simulation]
\label{simulation_LH}
  A low-level machine simulates a high-level machine with respect to a
  $simulation~relation~\sim$ between low-level machine states and
  high-level machine states, if $s^H_1 \sim s_1^L$ and
  \stepn{s^L_1}{s^L_2} implies that there exists $s^H_2$ such that,
  $s^H_2 \sim s^L_2$ and \stepn{s^H_1}{s^H_2}.

We visualize the above definition with the following diagram:

%
\vspace{-\smallskipamount}
 \begin{center}
    \begin{tikzpicture}
      \matrix (m) [matrix of math nodes,row sep=3em,column sep=4em,minimum width=2em]
      {
        s^L_1 & s^L_2 \\
        s^H_1 & s^H_2 \\};
      \path[->]
      (m-1-1) edge [snake it,-] node  {} (m-2-1)
      edge [above] node [below] {} (m-1-2)
      (m-2-1.east|-m-2-2) edge [dashed] node {}
      node {} (m-2-2)
      (m-1-2) edge [snake it,dashed,-] node {} (m-2-2);
    \end{tikzpicture}
  \end{center}
\vspace{-\smallskipamount}
(Plain lines denote premises, dashed ones conclusions.)
\end{definition}

Intuitively, backward simulation is enough to capture the desired
security property. Our intuition is further strengthened later, when
we prove that the \CFI property given by \cref{cfi} is preserved by
backward refinement. However, a machine that cannot take any step
also enjoys \CFI vacuously. Forward simulation would guarantee us that
if we start from two states in relation ($s^A_1 \sim s_1^S$), then a
step in the abstract machine (\stepn{s^A_1}{s^A_2}) is matched by a
step in the symbolic machine (\stepn{s^S_1}{s^S_2}) and the resulting
states are related by the simulation relation ($s^A_2 \sim s^S_2$). We
have not proved forward simulation but we believe it holds.

\TODO{Try to change that}

\subsubsection{Simulation Relation}
\label{sec:sim_relation}

We define the state simulation relation between the symbolic and
abstract machine by defining the simulation relation for each
component of the state.

\begin{definition}[Data Memory Simulation]\label{refine_dmemory}
  An abstract data memory \dmem is in simulation with a
  symbolic memory \mem, if for all words \textit{w, x} it holds
  that 
  $$\rd{\mem}{\mathit{w}} = \atom{x}{\DATA}
  \iff \rd{\dmem}{\mathit{w}} = \mathit{x}$$
\end{definition}

\begin{definition}[Instruction Memory Simulation]
  \label{refine_imemory}
  An abstract instruction memory \imem is in simulation with a
  symbolic memory \mem, if for all words \textit{w, x} it holds
  that
  $$(\exists~\mathit{it}, ~ \rd{\mem}{\mathit{w}} = 
  \atom{x}{(\INSTR{\mathit{it}})})
  \iff \rd{\imem}{\mathit{w}} = \mathit{x}$$
\end{definition}

\begin{definition}[Registers Simulation]
  \label{refine_registers}
  An abstract register set \textit{areg} is in simulation with a
  symbolic register set \textit{sreg}, if for all registers \textit{r} and words
  \textit{x} it holds that
  $$(\exists\mathit{ut \in (\id \cup \lbrace \bot \rbrace)}, 
  ~ \rd{\mathit{sreg}}{\mathit{r}} = 
  \atom{x}{ut})
  \iff \rd{\mathit{areg}}{\mathit{r}} = \mathit{x}$$
\end{definition}

\begin{definition}[PC simulation]
  \label{refine_pc}
  The abstract \pc (\textit{apc}) is in simulation with the symbolic \pc
  ($\atom{\mathit{spc}}{\tpc}$), if it holds that
  $$\mathit{apc} = \mathit{spc} \land
    (\tpc = \DATA \lor \exists\mathit{n \in \id},~
    \tpc = \INSTR{n})$$
\end{definition}

\Cref{refine_dmemory,refine_imemory,refine_registers,refine_pc} relate the basic
components of the state.  What is left to do, is relate the \ok bit of
the abstract machine with the state of the symbolic machine.

\begin{definition}[Correctness]
  \label{refine_correctness}
  The statement of correctness, states that for the symbolic memory
  (\textit{smem}), the symbolic pc ($\atom{spc}{\tpc}$) and the \ok bit
  of the abstract machine, it holds that for all words \textit{i} and
  tags \textit{ti},
  \begin{align*}
     & \rd{\mathit{smem}}{spc} = \atom{i}{ti} \implies \\
     & \ok = true  \iff \\
     & (\forall src \in \id, ~ \tpc = \INSTR{src} \implies  \\
     & ~~\exists dst \in \id, \\
     & ~~~~ \mathit{ti} = \INSTR{dst} \land (src,dst) \in \CFGm)
    \end{align*}
\end{definition}

Informally \cref{refine_correctness} states that if the tag on the
current instruction is \textit{ti}, then if the tag on the pc is set
to \INSTR{src} (which means an indirect flow occurred in the previous
step), there exists an \id dst which is used to tag the current
instruction and additionally the flow from an instruction with \id src
to one with \id dst is allowed according to \CFG, if and only if the
\ok bit of the abstract machine is set to true. This definition
captures the notion that a violation in the abstract machine is also a
violation in the symbolic machine and vice-versa.

We give one more definition of correctness, for the case of monitor
services.  The intuition is the same, but because monitor services
live outside the addressable memory of the machines, it's statement
needs to be adapted a bit.

\begin{definition}[Monitor Service Correctness]
  \label{refine_correctness_sc}
  Correctness for monitor services, states that for the symbolic memory
  (\textit{smem}), the symbolic pc ($\atom{spc}{\tpc}$) and the \ok bit
  of the abstract machine, it holds that for all monitor services
  \textit{sc},
  \begin{align*}
     & \rd{\mathit{smem}}{spc} = \varnothing \implies \\
     & \mathit{get\_service}~spc = (\mathit{ti},f) \implies \\
     & \ok = true  \iff \\
     & (\forall src \in \id, ~ \tpc = \INSTR{src} \implies  \\
     & ~~\exists dst \in \id, \\
     & ~~~~ \mathit{ti} = \INSTR{dst} \land (src,dst) \in \CFGm)
    \end{align*}
\end{definition}

The simulation relation ($\sim$) is defined as the conjunction of
\cref{refine_dmemory,refine_imemory,refine_registers,refine_pc,refine_correctness,refine_correctness_sc}
and the invariants
\labelcref{instructions_tagged,entry_tagged,valid_jmp_tagged}.

\subsubsection{Proving 1-backward simulation for normal steps}
\label{sec:backward_SA_normal}

Proving a 1-backward simulation for normal steps is relatively
straight-forward, mostly thanks to the fact that the symbolic
machine abstracts away many details of the concrete machine
that would make the proofs more tedious. Additionally we do
not have to provide such proofs for any monitor service as
we did not use any. Therefore we will only have to reason
about the small set of instructions that the symbolic
and the abstract machine share. 

We start with some helpful lemmas about registers and memory
updates. These lemmas serve as the basis for proving simulation for
instructions that change the registers or the memory.  The
corresponding Coq definitions and proofs can be found.
\TODO{cite appendix}

\begin{lemma}[Registers Update Backward Simulation]
\label{refine_registers_upd}
For all symbolic register sets (\textit{sreg,sreg'}),
abstract register sets (\textit{areg}), registers (\textit{r}),
words (\textit{v,v'}) and tags (\textit{tg,tg'}),
\begin{align*}
  & \mathit{areg} \sim_{regs} \mathit{sreg} \implies \\
  & \rd{\mathit{sreg}}{\mathit{r}} = \atom{v}{tg} \implies \\
  & \upd{\mathit{sreg}}{\mathit{r}}{\atom{v'}{tg'}} = \mathit{sreg'} \implies \\
  & ~~ \exists \mathit{areg'}, \\
  & ~~~~ \upd{\mathit{areg}}{\mathit{r}}{v'} = \mathit{areg'} \land \\
  & ~~~~  \mathit{areg'} \sim_{regs} \mathit{sreg'}
\end{align*}
\end{lemma}

\begin{lemma}[Memory Update Backward Simulation]
\label{refine_memory_upd}
For all symbolic memories (\textit{smem,smem'}),
abstract data memories (\textit{amem}) and
words (\textit{addr,v,v'}),
\begin{align*}
  & \mathit{amem} \sim_{dmem} \mathit{smem} \implies \\
  & \rd{\mathit{smem}}{\mathit{addr}} = \atom{v}{\DATA} \implies \\
  & \upd{\mathit{smem}}{\mathit{addr}}{\atom{v'}{\DATA}} = \mathit{smem'} \implies \\
  & ~~ \exists \mathit{amem'}, \\
  & ~~~~ \upd{\mathit{amem}}{\mathit{addr}}{v'} = \mathit{amem'} \land \\
  & ~~~~  \mathit{amem'} \sim_{dmem} \mathit{smem'}
\end{align*}
\end{lemma}

With these definitions and lemmas we are able to prove 1-backward simulation
for normal steps between the Symbolic and the Abstract machine as defined
by \cref{simulation_LH}, where the low-level machine is the Symbolic machine and
the high-level machine is the Abstract machine.

\begin{theorem}[1-Backward Simulation Symbolic-Abstract]
\label{simulation_SA}
\Cref{simulation_LH} holds for the Symbolic (low-level) and
the Abstract (high-level) machines.
\end{theorem}

\subsubsection{Proving 1-backward simulation for attacker steps}
\label{sec:backward_SA_attacker}

The same definition as \labelcref{simulation_LH} of 1-backward
simulation is used for the attacker, with the sole difference being
that steps now refer to attacker steps.

\begin{definition}[1-Backward Simulation Attacker]
\label{simulation_LH_attacker}
  The symbolic machine simulates the abstract machine with respect to
  a $simulation~relation~\sim$ between symbolic and abstract states,
  if $s^H_1 \sim s_1^L$ and \stepa{s^L_1}{s^L_2}{L} implies that there
  exists $s^H_2$ such that, $s^H_2 \sim s^L_2$ and \stepa{s^H_1}{s^H_2}{H}.
\end{definition}

We prove that 1-backward simulation for attacker steps hold, by first
showing how we can construct attacker steps at the abstract level from
symbolic attacker steps and then showing that this way of building
attacker steps preserves the simulation relation ($\sim$).

A step of the symbolic attacker, as mandated by the semantics of the
attacker model, can only change the memory and register contents tagged
\DATAname, formally \stepa{\mem}{\mem'}{S} and \stepa{\reg}{\reg'}{S}.

Intuitively, we can construct \textit{areg} by \emph{mapping} a function
on the set of registers, that changes a symbolic atom to a word by removing
it's tag. 

\lstheader{untag_atom}{Untag symbolic atom function}
Definition untag_atom (a : atom (word t) cfi_tag) := common.val a.
\end{lstlisting}

We can trivially prove that the abstract attacker can take a step
by \emph{mapping} untag\_atom over a symbolic register set. This is
trivial because the attacker can arbitrarily change all registers.

\begin{lemma}[Abstract attacker registers]
\label{areg_map}
  \begin{align*}
    & \stepa{\mathit{sreg}}{\mathit{sreg}'}{S} \implies \\
    & \stepa{\mathit{areg}}{\mathit{map}~untag\_atom~\mathit{sreg}'}{A}
  \end{align*}
\end{lemma}

However, we still need to prove that the simulation relation between
the two machines does not break when attacker steps are taken.
We can proof that simulation of registers is preserved by attacker
steps. The proof proceeds by using the correctness theorem for the map function.
\begin{theorem}[Map Correctness instance]
  $$\rd{(\mathit{map}~\mathit{untag\_atom}~\mathit{sreg}')}{r} = 
  \mathit{option\_map}~\mathit{untag\_atom}~ (\rd{\mathit{sreg}'}{r})$$
  where option\_map is defined as
  \lstheader{option_map}{Option Map function}
    Definition option_map f x := 
      match x with
      | Some y => Some (f y)
      | None => None
      end.
  \end{lstlisting}
\end{theorem}

\begin{lemma}[Attacker preserves register simulation]
\label{areg_map_preserves_ref}
  For all abstract register sets (\textit{areg})
  and symbolic register sets (\textit{sreg, sreg'}),
  \begin{align*}
    & \mathit{areg} \sim_{regs} \mathit{reg} \implies \\
    & \stepa{\mathit{sreg}}{\mathit{sreg}'}{S} \implies \\
    & \mathit{map}~untag\_atom~\mathit{sreg}' \sim_{regs} \mathit{sreg}'
  \end{align*}
\end{lemma}

In order to complete the proof of 1-backward simulation for attacker
steps, we also need to construct an abstract memory and to show
that the $\sim_{mem}$ relation is preserved by attacker steps.
Due to the fact that the abstract machine has split data and instruction
memories, in order to follow the same methodology as with registers,
we will need to split the symbolic memory. We achieve this, using a
filter function.

Firstly we proof that attacker steps do not break simulation of
instruction memories. Intuitively this is trivial, as the symbolic
attacker can only change memory contents tagged \DATAname.

\begin{lemma}[Attacker preserves instruction memory simulation]
\label{imem_attacker_ref}
  For all abstract instruction memories (\textit{imem})
  and symbolic memories (\textit{smem, smem'}),
  \begin{align*}
    & \mathit{imem} \sim_{imem} \mathit{smem} \implies \\
    & \stepa{\mathit{smem}}{\mathit{smem}'}{S} \implies \\
    & \mathit{imem} \sim_{imem} \mathit{smem}'
  \end{align*}
\end{lemma}

Constructing a data memory is more complicated than in the previous cases.
Our approach, uses the filter function to create a subset of the symbolic
memory that only contains atoms tagged \DATAname and then applies the
same methodology with registers, mapping the $untag\_atom$ function over
this subset to obtain an abstract data memory.

\lstheader{is_data}{Function that checks if atom is tagged \DATA}
Definition is_data (a : atom (word t) cfi_tag) :=
  match common.tag a with
    | DATA => true
    | INSTR _ => false
  end.
\end{lstlisting}

Again we can prove a few helpful lemmas that ease the final proof.

\begin{lemma}[Attacker preserves data memory simulation]
\label{dmem_attacker_preserves_ref}
  For all abstract data memories (\textit{dmem})
  and symbolic memories (\textit{smem, smem}'),
  \begin{align*}
    & \mathit{dmem} \sim_{dmem} \mathit{smem} \implies \\
    & \stepa{\mathit{smem}}{\mathit{smem}'}{S} \implies \\
    & \mathit{map}~untag\_atom~(\mathit{filter}~\mathit{is\_data}~\mathit{sreg}' \sim_{dmem} \mathit{dmem}'
  \end{align*}
\end{lemma}

The proof of \cref{dmem_attacker_preserves_ref} is slightly more complex than
the one for registers, as we now have to invoke the filter correctness theorem
as well.

\begin{theorem}[Filter Correctness instance]
  $$\rd{(\mathit{filter}~\mathit{is\_data}~\mathit{smem}')}{addr} = 
  \mathit{option\_filter}~\mathit{is\_data}~ (\rd{\mathit{smem}'}{addr})$$
  where option\_map is defined as
  \lstheader{option_filter}{Option Filter function}
    Definition option_filter f x := 
      match x with
      | Some x0 => if f x0 then Some x0 else None
      | None => None
      end.
  \end{lstlisting}
\end{theorem}

In all cases, we have to show that the domains of the abstract
memories and registers are also preserved. We include here the
corresponding lemma for the data memory. It's proof was again more
complicated, due to the fact that we had to split the symbolic memory.

\begin{lemma}[Attacker preserves data memory domains]
\label{dmem_attacker_preserves_domain}
  For all abstract data memories (\textit{dmem, dmem}')
  and symbolic memories (\textit{smem, smem}'),
  \begin{align*}
    & \mathit{dmem} \sim_{dmem} \mathit{smem} \implies \\
    & \stepa{\mathit{smem}}{\mathit{smem}'}{S} \implies \\
    & \mathit{dmem}' \sim_{dmem} \mathit{smem}' \implies \\
    & \mathcal{D}(\mathit{dmem}) = \mathcal{D}(\mathit{dmem}')
  \end{align*}
\end{lemma}

Likewise with normal steps, we can now prove a 1-backward
simulation for attacker steps as defined by \cref{simulation_LH_attacker}.

\begin{theorem}[1-Backward Simulation Symbolic-Abstract for Attacker]
\label{simulation_SA_attacker}
\Cref{simulation_LH_attacker} holds for the Symbolic (low-level) and
the Abstract (high-level) machines.
\end{theorem}

\section{The Concrete  Machine}\label{sec:concrete_cfi}

Assuming the existence of correct code that implements the \CFI
monitor, we can utilize the framework of \cref{sec:framework} to
instantiate the concrete machine and obtain a refinement between the
concrete and the symbolic machines, we need to provide the encoding of
symbolic tags. For the concrete machine we only considered a 32-bit
architecture, but as already mentioned, we could very easily
instantiate the concrete machine with 64-bit words with minimal
changes to our proofs.

\subsection{Concrete tags}\label{sec:concrete_tags}

In order to obtain the concrete tags, we need to wrap the symbolic
tags with the monitor self-protection tags (\USERname, \ENTRYname,
\MONITOR) and provide an encoding to words of these tags.

We instantiate the \id type of cfi\_id class (\cref{id_class}) as
bit-fields of size 28-bits. That means, that we can uniquely identify
up to $2^{28}$ instructions. Trying to tag more instructions than
this, would break the symbolic
invariant \labelcref{instructions_tagged}, because by the simulation
relation between the concrete and symbolic machines, the
two machines follow the same tagging scheme for \USERname and \ENTRYname tags.

Defining the conversion functions \footnote{Numbers in the Coq
  definitions are off by one (\EG 27 means 28), for reasons relating
  to the underlying words library \TODO{cite library}} between
\textit{words} and \textit{ids} is straight forward. We make the
simply choice, to convert \textit{words} to \textit{ids} only if they
are equal or less than the maximum word our 28-bit \textit{ids} can
fit. Note that this does not mean we reduce the addressable space to
28-bits. You can use addresses higher than $2^{28}$ to place contents
tagged as \DATAname or \MONITOR or even \INSTR{$\bot$} but not
instructions with an identifier.

The conversion from \textit{ids} to \textit{words} is trivial by
expanding the id to 32-bit words by adding zeros to the high bits.

\QUESTION{To Catalin: Do the above make sense to you?}

\lstheader{id_conversion}{Coq definitions of conversion functions for ids and words}
Definition id_size := Word.int 27.
Definition id := [eqType of id_size].
Definition bound : word t := 
  Word.repr ((Word.max_unsigned 27) + 1)%Z. (*29 bits*)

Definition word_to_id (w : word t) : option id_size :=
  if (Word.ltu w bound) then Some (Word.castu w) else None.

Definition id_to_word (x : id) : word t :=
  Word.castu x.
\end{lstlisting}

Finally we prove the two properties required by cfi\_id,
\textit{id\_to\_wordK} and \textit{word\_to\_idK}. We can now
instantiate cfi\_id with 28-bit sized \textit{ids}.

\lstheader{cfi_id28}{cfi\_id instance with 28-bit sized \textit{ids}} 
Instance ids : cfi_id := {|
 id := id;
 word_to_id := word_to_id;
 id_to_word := id_to_word
|}.
Proof.
  - by apply id_to_wordK.
  - by apply word_to_idK.
Defined.
\end{lstlisting}

When using identifiers of 28-bits, we can encode the symbolic tags using
30 bits, with an encoding like the one in \cref{tag_encoding}, where
the two least-significant bits are used to distinguish between \DATA,
\INSTR{$\bot$} and \INSTR{\id}, and the 28 higher-bits are the \id
in the last case and zero otherwise.

\begin{table}[htb!]
\centering
    \begin{tabular}{|c|c|}
    \hline
    Symbolic Tag   & Encoding \\ \hline
    \DATA           & 0        \\ \hline
    \INSTR{$\bot$}     & 1        \\ \hline
    \INSTR{\id} & $4x+2$    \\ \hline
    \end{tabular}
  \caption{Encoding of Symbolic Tags}
  \label{tag_encoding}
\end{table}

Having an encoding into 30-bits of symbolic tags, we can use the
2-bits left, to wrap the symbolic tags with the monitor
self-protection tags. We use the two least-significant bits to
distinguish between \USERname (01), \ENTRYname (10) and \MONITOR
(00). Only the \USERname and \ENTRYname wrap around symbolic tags. The
policy monitor does not use symbolic tags and the corresponding tag
\MONITOR does not need to wrap around them. Thus the encoding of the
\MONITOR tag has all its bits set to zero.

\begin{figure}[htb!]
  \centering
  \begin{bytefield}[endianness=big]{32}
    \bitheader{0,1,2,3,31} \\
    \bitbox{28}{id} & \bitbox{1}{1} & \bitbox{1}{0} & \bitbox{1}{0} & \bitbox{1}{1} \\    
  \end{bytefield}
  \label{instr_example}
  \caption{Encoding of an instruction with a unique identifier id}
\end{figure}

With the above encoding, we can easily define a \emph{decode} function
and prove that the \emph{decode} function is the \emph{left inverse}
of the \emph{encode} function ($decode (encode~t) = t$) and
\emph{right inverse} for all elements in the domain of \emph{decode}
($decode~w = t \implies encode~t = w$).

\subsection{Concrete-Symbolic backward refinement}\label{sec:refinement_CS}

We can now instantiate the backward refinement between the concrete
and the symbolic machine that is provided by the micro-policies
framework \cite{pump_popl2015}. For the concrete to symbolic backward
refinement we no longer get a 1-backward simulation, due to the fact
that the steps the concrete policy monitor takes are not matched by
any steps of the symbolic machine. We can however proof a 1-backward
simulation as defined by \cref{simulation_LH}, where the low-level
machine is now the concrete machine and the high-level one the
symbolic machine, with respect to a simulation relation ($\sim_U$)
when the tag of the \pc is \USERname (user state).

For \MONITOR steps we can use a weaker simulation relation ($\sim_M$)
and eventually obtain a $\lbrace 0,1 \rbrace$-backward simulation.

\begin{definition}[Weak simulation relation for Monitor steps]
\label{weak_simulation_relation}
  A concrete state $s^C$ is in weak simulation with a symbolic state $s^S$
  ($s^S \sim_M s^C$), if the tag of the \pc of state $s^C$ is \MONITOR and
  there exists a concrete user state $s_0^C$ such that $s^S \sim_U s^C_0$
  and there is an execution trace $s^C_0 \to_n \ldots \to_n s^C$ with only
  monitor steps (all states have \MONITOR tag on the \pc).
  
  We visualize the above definition with the following diagram:

%
\vspace{-\smallskipamount}
 \begin{center}
    \begin{tikzpicture}
      \matrix (m) [matrix of math nodes,row sep=3em,column sep=4em,minimum width=2em]
      {
        & s^S \\
        s^C_0 & s^C_1 & s^C \\};
      \path[->]
      (m-1-2) edge [snake it,-,above,sloped,font=\tiny] node {U} (m-2-1)
      (m-2-1.east|-m-2-2) edge [below,font=\tiny] node {UM}
      node {} (m-2-2)
      (m-1-2) edge [snake it,-,left,font=\tiny] node {M} (m-2-2)
      (m-2-2.east|-m-2-3) edge [below,font=\tiny] node {$M^*$}
      node {} (m-2-3)
      (m-1-2) edge [snake it,-,above,sloped,font=\tiny] node {M} (m-2-3);
    \end{tikzpicture}
  \end{center}
\vspace{-\smallskipamount}
\end{definition}

